# ARIA ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¬ã‚¤ãƒ‰

> **ARIA** - AI Research & Inquiry Assistant  
> ç ”ç©¶è€…ã®ãŸã‚ã® AI ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ 

## ğŸ“š ç›®æ¬¡

1. [ã¯ã˜ã‚ã«](#ã¯ã˜ã‚ã«)
2. [ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«](#ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«)
3. [ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ](#ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ)
4. [ä¸»è¦æ©Ÿèƒ½](#ä¸»è¦æ©Ÿèƒ½)
5. [MCP ãƒ„ãƒ¼ãƒ«ã®ä½¿ã„æ–¹](#mcp-ãƒ„ãƒ¼ãƒ«ã®ä½¿ã„æ–¹)
6. [è¨­å®š](#è¨­å®š)
7. [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)

---

## ã¯ã˜ã‚ã«

ARIA ã¯ç ”ç©¶æ´»å‹•ã‚’æ”¯æ´ã™ã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚

- ğŸ“ **å®Ÿé¨“ãƒãƒ¼ãƒˆç®¡ç†** - æ§‹é€ åŒ–ã•ã‚ŒãŸå®Ÿé¨“è¨˜éŒ²ã®ä½œæˆãƒ»æ¤œç´¢
- ğŸ“„ **è«–æ–‡å‡¦ç†** - PDF ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã€åˆ†æã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
- ğŸ§  **ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•** - GraphRAG ã«ã‚ˆã‚‹çŸ¥è­˜ã®é–¢é€£ä»˜ã‘ã¨æ¤œç´¢
- ğŸ¤– **LLM çµ±åˆ** - è¤‡æ•°ã® LLM ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã«å¯¾å¿œ

---

## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

### å‰ææ¡ä»¶

- Node.js 20.x ä»¥ä¸Š
- pnpm 9.x ä»¥ä¸Š
- Python 3.10 ä»¥ä¸Šï¼ˆdocling/graphrag ä½¿ç”¨æ™‚ï¼‰

### æ‰‹é †

```bash
# ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/nahisaho/ARIA.git
cd ARIA/aria

# ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pnpm install

# ãƒ“ãƒ«ãƒ‰
pnpm build

# Python ä»®æƒ³ç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
python3 -m venv .venv
source .venv/bin/activate
pip install docling graphrag
```

---

## ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### 1. MCP ã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•

VS Code ã§ ARIA ã® MCP ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ï¼š

```bash
# MCP ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
pnpm --filter @aria/mcp-server start
```

VS Code ã® `settings.json` ã«è¿½åŠ ï¼š

```json
{
  "github.copilot.chat.mcpServers": {
    "aria": {
      "command": "node",
      "args": ["/path/to/aria/packages/mcp-server/dist/cli.js"],
      "env": {
        "STORAGE_PATH": "/path/to/aria/storage"
      }
    }
  }
}
```

### 2. æœ€åˆã®å®Ÿé¨“ãƒãƒ¼ãƒˆã‚’ä½œæˆ

GitHub Copilot Chat ã§ï¼š

```
@aria æ–°ã—ã„å®Ÿé¨“ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
ã‚¿ã‚¤ãƒˆãƒ«: Transformer ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ç‡æœ€é©åŒ–
ä»®èª¬: å­¦ç¿’ç‡ warmup ã‚’ä½¿ç”¨ã™ã‚‹ã¨åæŸãŒæ—©ããªã‚‹
```

### 3. è«–æ–‡ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

```
@aria arXiv:2312.10997 ã®è«–æ–‡ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦åˆ†æã—ã¦ãã ã•ã„
```

### 4. è¤‡æ•°ã®è«–æ–‡ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¾Œã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ

```
# è¤‡æ•°ã®è«–æ–‡ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
@aria ä»¥ä¸‹ã®è«–æ–‡ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ:
- arXiv:1706.03762 (Attention Is All You Need)
- arXiv:1810.04805 (BERT)
- arXiv:2005.14165 (GPT-3)

# ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†å¾Œã€GraphRAG ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ
@aria ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ãŸè«–æ–‡ã§ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¦ãã ã•ã„
```

> **æ³¨æ„**: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã¯ã€è¤‡æ•°ã®è«–æ–‡ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ãŸå¾Œã«ã¾ã¨ã‚ã¦å®Ÿè¡Œã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã«ã¯ LLM API ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã€è«–æ–‡ã”ã¨ã«å®Ÿè¡Œã™ã‚‹ã‚ˆã‚Šã‚‚åŠ¹ç‡çš„ã§ã™ã€‚

---

## ä¸»è¦æ©Ÿèƒ½

### ğŸ“ å®Ÿé¨“ãƒãƒ¼ãƒˆç®¡ç†

å®Ÿé¨“ã®ä»®èª¬ã€æ–¹æ³•è«–ã€çµæœã€çµè«–ã‚’æ§‹é€ åŒ–ã—ã¦è¨˜éŒ²ã—ã¾ã™ã€‚

**ä½œæˆä¾‹ï¼š**
```yaml
id: EXP-20260130-001
title: Transformer å­¦ç¿’ç‡æœ€é©åŒ–å®Ÿé¨“
status: in_progress
hypothesis: warmup ã‚’ä½¿ç”¨ã™ã‚‹ã¨åæŸãŒæ—©ããªã‚‹
methodology:
  - ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: å›ºå®šå­¦ç¿’ç‡ 1e-4
  - å®Ÿé¨“ç¾¤: warmup 1000 steps + cosine decay
variables:
  independent:
    - warmup_steps: [500, 1000, 2000]
  dependent:
    - validation_loss
    - convergence_epoch
```

**æ¤œç´¢ï¼š**
```
@aria ã€Œå­¦ç¿’ç‡ã€ã«é–¢ã™ã‚‹å®Ÿé¨“ã‚’æ¤œç´¢
```

### ğŸ“„ è«–æ–‡å‡¦ç†

PDF è«–æ–‡ã‚’ Markdown ã«å¤‰æ›ã—ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¾ã™ã€‚

**å¯¾å¿œå½¢å¼ï¼š**
- arXiv IDï¼ˆä¾‹: `2312.10997`ï¼‰
- DOIï¼ˆä¾‹: `10.1000/xyz123`ï¼‰
- PMC IDï¼ˆä¾‹: `PMC12345`ï¼‰
- ãƒ­ãƒ¼ã‚«ãƒ« PDF ãƒ•ã‚¡ã‚¤ãƒ«

**åˆ†æå†…å®¹ï¼š**
- ã‚¿ã‚¤ãƒˆãƒ«ã€è‘—è€…ã€æ‰€å±
- ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆ
- ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ§‹é€ 
- å›³è¡¨ã€æ•°å¼
- å‚è€ƒæ–‡çŒ®

### ğŸ§  ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ• (GraphRAG)

è«–æ–‡ã‚„å®Ÿé¨“ã‹ã‚‰æŠ½å‡ºã—ãŸçŸ¥è­˜ã‚’ã‚°ãƒ©ãƒ•ã¨ã—ã¦ç®¡ç†ã—ã¾ã™ã€‚

**ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚¿ã‚¤ãƒ—ï¼š**
- `concept` - æ¦‚å¿µã€ç†è«–
- `method` - æ‰‹æ³•ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
- `finding` - ç™ºè¦‹ã€çµæœ
- `relation` - ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£é–“ã®é–¢ä¿‚

**ã‚¯ã‚¨ãƒªãƒ¢ãƒ¼ãƒ‰ï¼š**

| ãƒ¢ãƒ¼ãƒ‰ | ç”¨é€” | ä¾‹ |
|--------|------|-----|
| Local | ç‰¹å®šã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã«ã¤ã„ã¦è©³ç´°ã‚’èª¿ã¹ã‚‹ | ã€ŒAttention æ©Ÿæ§‹ã¨ã¯ä½•ã‹ï¼Ÿã€ |
| Global | ãƒ†ãƒ¼ãƒå…¨ä½“ã®æ¦‚è¦ã‚’æŠŠæ¡ã™ã‚‹ | ã€Œã“ã®åˆ†é‡ã®ä¸»è¦ãªç ”ç©¶ãƒˆãƒ¬ãƒ³ãƒ‰ã¯ï¼Ÿã€ |
| DRIFT | æ¢ç´¢çš„ã«é–¢é€£çŸ¥è­˜ã‚’ç™ºè¦‹ã™ã‚‹ | ã€ŒTransformer ã®å¿œç”¨åˆ†é‡ã‚’æ¢ç´¢ã€ |

### ğŸ¤– LLM ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼

è¤‡æ•°ã® LLM ã«å¯¾å¿œã—ã€è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ã‚µãƒãƒ¼ãƒˆï¼š

| ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ | ãƒ¢ãƒ‡ãƒ«ä¾‹ | ç”¨é€” |
|--------------|----------|------|
| OpenAI | gpt-4o | é«˜å“è³ªãªåˆ†æ |
| Azure OpenAI | gpt-4o | ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚º |
| Anthropic | claude-3-5-sonnet | é•·æ–‡å‡¦ç† |
| Ollama | llama3.2 | ãƒ­ãƒ¼ã‚«ãƒ«æ¨è«– |

---

## MCP ãƒ„ãƒ¼ãƒ«ã®ä½¿ã„æ–¹

### å®Ÿé¨“ãƒ„ãƒ¼ãƒ«

#### `experiment_create`
æ–°ã—ã„å®Ÿé¨“ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚

```
@aria å®Ÿé¨“ã‚’ä½œæˆ:
- ã‚¿ã‚¤ãƒˆãƒ«: BERT ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿé¨“
- ä»®èª¬: ãƒ‰ãƒ¡ã‚¤ãƒ³å›ºæœ‰ãƒ‡ãƒ¼ã‚¿ã§äº‹å‰å­¦ç¿’ã™ã‚‹ã¨ç²¾åº¦ãŒå‘ä¸Šã™ã‚‹
- çŠ¶æ…‹: planned
```

#### `experiment_update`
æ—¢å­˜ã®å®Ÿé¨“ã‚’æ›´æ–°ã—ã¾ã™ã€‚

```
@aria å®Ÿé¨“ EXP-20260130-001 ã‚’æ›´æ–°:
- çŠ¶æ…‹: completed
- çµæœ: warmup 1000 steps ãŒæœ€é©ã€åæŸãŒ 20% æ—©ããªã£ãŸ
```

#### `experiment_search`
å®Ÿé¨“ã‚’æ¤œç´¢ã—ã¾ã™ã€‚

```
@aria ã€ŒBERTã€ã«é–¢ã™ã‚‹å®Ÿé¨“ã‚’æ¤œç´¢
```

### çŸ¥è­˜ãƒ„ãƒ¼ãƒ«

#### `knowledge_add`
çŸ¥è­˜ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’è¿½åŠ ã—ã¾ã™ã€‚

```
@aria çŸ¥è­˜ã‚’è¿½åŠ :
- åå‰: Self-Attention
- ã‚¿ã‚¤ãƒ—: concept
- èª¬æ˜: ã‚¯ã‚¨ãƒªã€ã‚­ãƒ¼ã€ãƒãƒªãƒ¥ãƒ¼ã‚’ä½¿ã£ãŸæ³¨æ„æ©Ÿæ§‹
- ã‚¿ã‚°: transformer, attention, deep-learning
```

#### `knowledge_search`
çŸ¥è­˜ã‚’æ¤œç´¢ã—ã¾ã™ã€‚

```
@aria ã€Œattentionã€ã«é–¢ã™ã‚‹çŸ¥è­˜ã‚’æ¤œç´¢
```

#### `knowledge_relate`
ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£é–“ã®é–¢ä¿‚ã‚’ä½œæˆã—ã¾ã™ã€‚

```
@aria é–¢ä¿‚ã‚’ä½œæˆ:
Self-Attention --[is_component_of]--> Transformer
```

### è«–æ–‡ãƒ„ãƒ¼ãƒ«

#### `paper_import`
è«–æ–‡ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦å‡¦ç†ã—ã¾ã™ã€‚

```
@aria è«–æ–‡ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ: arXiv:1706.03762
```

#### `paper_analyze`
ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ãŸè«–æ–‡ã‚’è©³ç´°åˆ†æã—ã¾ã™ã€‚

```
@aria è«–æ–‡ PAPER-001 ã‚’åˆ†æã—ã¦ã€ä¸»è¦ãªè²¢çŒ®ã‚’æŠ½å‡º
```

### GraphRAG ãƒ„ãƒ¼ãƒ«

#### `graphrag_index`
ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ãŸè«–æ–‡ã‹ã‚‰ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¾ã™ã€‚

> **æ¨å¥¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼**: 
> 1. `paper_import` ã§è¤‡æ•°ã®è«–æ–‡ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
> 2. `graphrag_index` ã§ã¾ã¨ã‚ã¦ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ
> 3. `graphrag_query` ã§æ¤œç´¢

```
# ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ¸ˆã¿ã®è«–æ–‡ã‹ã‚‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ
@aria ./storage/papers/processed ãƒ•ã‚©ãƒ«ãƒ€ã®è«–æ–‡ã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ

# ã¾ãŸã¯ç‰¹å®šã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®š
@aria ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ:
- storage/papers/processed/attention-paper.md
- storage/papers/processed/bert-paper.md
```

#### `graphrag_query`
ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ã«ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

```
@aria GraphRAGæ¤œç´¢ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰: Transformer ã®è¨ˆç®—åŠ¹ç‡æ”¹å–„æ‰‹æ³•
```

---

## è¨­å®š

### è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«

`config/aria.config.yaml` ã§å„ç¨®è¨­å®šã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã§ãã¾ã™ã€‚

---

### LLM ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®š

#### ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®é¸æŠ

```yaml
llm:
  default_provider: "openai"  # openai, azure-openai, anthropic, ollama ã‹ã‚‰é¸æŠ
```

#### OpenAI

```yaml
llm:
  providers:
    openai:
      type: "openai"
      api_key: "${OPENAI_API_KEY}"  # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã¿
      models:
        chat: "gpt-4o"              # ãƒãƒ£ãƒƒãƒˆç”¨ãƒ¢ãƒ‡ãƒ«
        embedding: "text-embedding-3-large"  # åŸ‹ã‚è¾¼ã¿ç”¨ãƒ¢ãƒ‡ãƒ«
```

**ç’°å¢ƒå¤‰æ•°ã®è¨­å®šï¼š**
```bash
export OPENAI_API_KEY="sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
```

**åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ï¼š**
| ç”¨é€” | ãƒ¢ãƒ‡ãƒ« | ç‰¹å¾´ |
|------|--------|------|
| ãƒãƒ£ãƒƒãƒˆ | `gpt-4o` | æœ€é«˜æ€§èƒ½ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ« |
| ãƒãƒ£ãƒƒãƒˆ | `gpt-4o-mini` | ã‚³ã‚¹ãƒˆåŠ¹ç‡é‡è¦– |
| ãƒãƒ£ãƒƒãƒˆ | `gpt-4-turbo` | é•·æ–‡å¯¾å¿œ |
| åŸ‹ã‚è¾¼ã¿ | `text-embedding-3-large` | é«˜ç²¾åº¦ |
| åŸ‹ã‚è¾¼ã¿ | `text-embedding-3-small` | ä½ã‚³ã‚¹ãƒˆ |

#### Azure OpenAI

```yaml
llm:
  providers:
    azure-openai:
      type: "azure-openai"
      endpoint: "${AZURE_OPENAI_ENDPOINT}"
      api_key: "${AZURE_OPENAI_API_KEY}"
      api_version: "2024-02-15-preview"
      deployments:
        chat: "gpt-4o"              # ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå
        embedding: "text-embedding-3-large"
```

**ç’°å¢ƒå¤‰æ•°ã®è¨­å®šï¼š**
```bash
export AZURE_OPENAI_ENDPOINT="https://your-resource.openai.azure.com"
export AZURE_OPENAI_API_KEY="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
```

> **æ³¨æ„**: `deployments` ã«ã¯ Azure ãƒãƒ¼ã‚¿ãƒ«ã§ä½œæˆã—ãŸãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆåã‚’æŒ‡å®šã—ã¾ã™ã€‚

#### Microsoft Foundry (Azure AI Foundry)

Microsoft Foundry ã¯ Azure AI ã®çµ±åˆãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã€Azure OpenAI ãƒ¢ãƒ‡ãƒ«ã«åŠ ãˆã¦ã€Meta Llamaã€DeepSeekã€Grok ãªã©ã® Foundry Models ã‚’åˆ©ç”¨ã§ãã¾ã™ã€‚

```yaml
llm:
  providers:
    azure-foundry:
      type: "azure-foundry"
      endpoint: "${AZURE_FOUNDRY_ENDPOINT}"  # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
      api_key: "${AZURE_FOUNDRY_API_KEY}"    # ã¾ãŸã¯ Microsoft Entra ID èªè¨¼
      deployments:
        chat: "MAI-DS-R1"           # ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå
        embedding: "text-embedding-3-large"
```

**ç’°å¢ƒå¤‰æ•°ã®è¨­å®šï¼š**
```bash
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆFoundry ãƒãƒ¼ã‚¿ãƒ«ã§ç¢ºèªï¼‰
export AZURE_FOUNDRY_ENDPOINT="https://YOUR-RESOURCE-NAME.services.ai.azure.com/api/projects/YOUR_PROJECT_NAME"
export AZURE_FOUNDRY_API_KEY="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
```

**ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †ï¼š**

1. [Microsoft Foundry ãƒãƒ¼ã‚¿ãƒ«](https://ai.azure.com/) ã«ã‚µã‚¤ãƒ³ã‚¤ãƒ³
2. **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ**ï¼ˆã¾ãŸã¯æ—¢å­˜ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é¸æŠï¼‰
3. **Model catalog** ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ
4. **Use this model** â†’ **Deploy** ã§ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆ
5. **Models + Endpoints** ã§ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ URL ã¨ API ã‚­ãƒ¼ã‚’ç¢ºèª

**åˆ©ç”¨å¯èƒ½ãª Foundry Modelsï¼š**

| ã‚«ãƒ†ã‚´ãƒª | ãƒ¢ãƒ‡ãƒ« | ç‰¹å¾´ |
|----------|--------|------|
| **Azure ç›´æ¥è²©å£²** | `gpt-4o`, `gpt-4o-mini` | Azure OpenAI ãƒ¢ãƒ‡ãƒ« |
| **Microsoft AI** | `MAI-DS-R1` | é«˜ç²¾åº¦æ¨è«– |
| **Grok** | `grok-4`, `grok-3` | ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢æ¨è«– |
| **DeepSeek** | `DeepSeek-V3`, `DeepSeek-R1` | ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ« |
| **Meta Llama** | `Llama-3.3-70B-Instruct` | ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºå‘ã‘ |

**Python SDK ã§ã®ä½¿ç”¨ä¾‹ï¼š**
```python
from azure.identity import DefaultAzureCredential
from azure.ai.projects import AIProjectClient

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
project_client = AIProjectClient(
    endpoint="https://YOUR-RESOURCE-NAME.services.ai.azure.com/api/projects/YOUR_PROJECT_NAME",
    credential=DefaultAzureCredential(),  # ã‚­ãƒ¼ãƒ¬ã‚¹èªè¨¼æ¨å¥¨
)

# OpenAI äº’æ›ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—
openai_client = project_client.get_openai_client()

# Responses API ã§ç”Ÿæˆ
response = openai_client.responses.create(
    model="MAI-DS-R1",  # ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå
    input="What is the capital of France?",
)
print(response.model_dump_json(indent=2))
```

> **å‚è€ƒ**: [Microsoft Foundry ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://learn.microsoft.com/azure/ai-foundry/)

#### Anthropic Claude

```yaml
llm:
  providers:
    anthropic:
      type: "anthropic"
      api_key: "${ANTHROPIC_API_KEY}"
      models:
        chat: "claude-3-5-sonnet-20241022"
```

**ç’°å¢ƒå¤‰æ•°ã®è¨­å®šï¼š**
```bash
export ANTHROPIC_API_KEY="sk-ant-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
```

**åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ï¼š**
| ãƒ¢ãƒ‡ãƒ« | ç‰¹å¾´ |
|--------|------|
| `claude-3-5-sonnet-20241022` | ãƒãƒ©ãƒ³ã‚¹å‹ã€æ¨å¥¨ |
| `claude-3-opus-20240229` | æœ€é«˜æ€§èƒ½ |
| `claude-3-haiku-20240307` | é«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆ |

#### Ollamaï¼ˆãƒ­ãƒ¼ã‚«ãƒ«æ¨è«–ï¼‰

```yaml
llm:
  providers:
    ollama:
      type: "ollama"
      base_url: "http://localhost:11434"  # Ollama ã‚µãƒ¼ãƒãƒ¼ã®URL
      models:
        chat: "llama3.2"
        embedding: "nomic-embed-text"
```

**Ollama ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼š**
```bash
# Ollama ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
curl -fsSL https://ollama.com/install.sh | sh

# ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
ollama pull llama3.2
ollama pull nomic-embed-text

# ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ï¼ˆé€šå¸¸ã¯è‡ªå‹•èµ·å‹•ï¼‰
ollama serve
```

**åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ï¼ˆä¾‹ï¼‰ï¼š**
| ç”¨é€” | ãƒ¢ãƒ‡ãƒ« | ã‚µã‚¤ã‚º |
|------|--------|--------|
| ãƒãƒ£ãƒƒãƒˆ | `llama3.2` | 3B |
| ãƒãƒ£ãƒƒãƒˆ | `llama3.2:70b` | 70B |
| ãƒãƒ£ãƒƒãƒˆ | `mistral` | 7B |
| ãƒãƒ£ãƒƒãƒˆ | `codellama` | 7B |
| åŸ‹ã‚è¾¼ã¿ | `nomic-embed-text` | 137M |
| åŸ‹ã‚è¾¼ã¿ | `mxbai-embed-large` | 335M |

#### ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®š

è¤‡æ•°ã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’è¨­å®šã—ã€éšœå®³æ™‚ã«è‡ªå‹•åˆ‡ã‚Šæ›¿ãˆï¼š

```yaml
llm:
  default_provider: "openai"
  
  fallback:
    enabled: true
    order:
      - openai      # æœ€åˆã«è©¦è¡Œ
      - azure-openai
      - anthropic
      - ollama      # æœ€å¾Œã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    retry_count: 3
    retry_delay_ms: 1000
```

---

### GraphRAG è¨­å®š

```yaml
graphrag:
  indexing:
    chunk_size: 300
    chunk_overlap: 50
  
  query:
    local_search:
      max_results: 10
      similarity_threshold: 0.7
```

### ç’°å¢ƒå¤‰æ•°

```bash
# .env ãƒ•ã‚¡ã‚¤ãƒ«
OPENAI_API_KEY=sk-xxx
AZURE_OPENAI_ENDPOINT=https://xxx.openai.azure.com
AZURE_OPENAI_API_KEY=xxx
ANTHROPIC_API_KEY=sk-ant-xxx
```

---

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œ

#### MCP ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ããªã„

1. ã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªï¼š
   ```bash
   pnpm --filter @aria/mcp-server start
   ```

2. VS Code ã®è¨­å®šãƒ‘ã‚¹ãŒæ­£ã—ã„ã‹ç¢ºèª

3. ãƒ­ã‚°ã‚’ç¢ºèªï¼š
   ```bash
   cat logs/aria.log
   ```

#### docling ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹

1. Python ä»®æƒ³ç’°å¢ƒãŒæœ‰åŠ¹ã‹ç¢ºèªï¼š
   ```bash
   source .venv/bin/activate
   which python
   ```

2. docling ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªï¼š
   ```bash
   pip show docling
   ```

#### GraphRAG ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒå¤±æ•—ã™ã‚‹

1. OpenAI API ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªï¼š
   ```bash
   echo $OPENAI_API_KEY
   ```

2. å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªï¼š
   ```bash
   ls storage/knowledge-graph/input/
   ```

### ãƒ­ã‚°ã®ç¢ºèª

```bash
# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚°
tail -f logs/aria.log

# ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•
DEBUG=* pnpm --filter @aria/mcp-server start
```

### ã‚µãƒãƒ¼ãƒˆ

- **Issues**: https://github.com/nahisaho/ARIA/issues
- **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: https://github.com/nahisaho/ARIA/tree/main/docs

---

## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. [API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹](./API.md) ã‚’å‚ç…§
2. [è¦ä»¶å®šç¾©æ›¸](./requirements/) ã§è©³ç´°ã‚’ç¢ºèª
3. [CHANGELOG](../CHANGELOG.md) ã§æœ€æ–°ã®å¤‰æ›´ã‚’ç¢ºèª

---

*ARIA v0.1.0 | æœ€çµ‚æ›´æ–°: 2026-01-30*
