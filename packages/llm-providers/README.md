# @aria/llm-providers

> ãƒãƒ«ãƒ LLM ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å¯¾å¿œãƒ©ã‚¤ãƒ–ãƒ©ãƒª - OpenAI, Azure OpenAI, Anthropic, Ollama

## ğŸ“¦ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
pnpm add @aria/llm-providers
```

## ğŸ¯ æ¦‚è¦

`@aria/llm-providers` ã¯è¤‡æ•°ã® LLM ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§åˆ©ç”¨ã™ã‚‹ãŸã‚ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã§ã™ã€‚

### ã‚µãƒãƒ¼ãƒˆãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼

| ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ | ãƒãƒ£ãƒƒãƒˆ | åŸ‹ã‚è¾¼ã¿ | ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚° |
|--------------|----------|----------|----------------|
| OpenAI | âœ… | âœ… | âœ… |
| Azure OpenAI | âœ… | âœ… | âœ… |
| Anthropic | âœ… | âŒ | âœ… |
| Ollama | âœ… | âœ… | âœ… |

## ğŸ“– ä½¿ç”¨æ–¹æ³•

### ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼é–¢æ•°

```typescript
import { createLLMProvider, createLLMProviderFromEnv } from '@aria/llm-providers';

// è¨­å®šã‹ã‚‰ä½œæˆ
const provider = createLLMProvider({
  type: 'openai',
  apiKey: 'sk-...',
  models: {
    chat: 'gpt-4o',
    embedding: 'text-embedding-3-small',
  },
});

// ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ä½œæˆ
const providerFromEnv = createLLMProviderFromEnv();
```

### ãƒãƒ£ãƒƒãƒˆè£œå®Œ

```typescript
const result = await provider.chat([
  { role: 'system', content: 'You are a helpful assistant.' },
  { role: 'user', content: 'What is GraphRAG?' },
]);

console.log(result.content);
```

### ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°

```typescript
for await (const chunk of provider.streamChat([
  { role: 'user', content: 'Explain transformers in detail.' },
])) {
  process.stdout.write(chunk.content);
}
```

### åŸ‹ã‚è¾¼ã¿

```typescript
const embeddings = await provider.embed([
  'First document',
  'Second document',
]);

console.log(embeddings[0].length); // åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒæ•°
```

### ä½¿ç”¨é‡ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°

```typescript
const usage = await provider.getUsage();
console.log(`Total tokens: ${usage.totalTokens}`);
```

## âš™ï¸ ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®š

### OpenAI

```typescript
const openai = createLLMProvider({
  type: 'openai',
  apiKey: process.env.OPENAI_API_KEY,
  baseUrl: 'https://api.openai.com/v1',  // ã‚ªãƒ—ã‚·ãƒ§ãƒ³
  models: {
    chat: 'gpt-4o',
    embedding: 'text-embedding-3-small',
  },
});
```

**ç’°å¢ƒå¤‰æ•°:**
- `OPENAI_API_KEY` (å¿…é ˆ)
- `OPENAI_BASE_URL` (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
- `OPENAI_CHAT_MODEL` (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
- `OPENAI_EMBEDDING_MODEL` (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)

### Azure OpenAI

```typescript
const azure = createLLMProvider({
  type: 'azure-openai',
  endpoint: 'https://your-resource.openai.azure.com',
  apiKey: process.env.AZURE_OPENAI_API_KEY,
  apiVersion: '2024-02-15-preview',
  deployments: {
    chat: 'gpt-4o',
    embedding: 'text-embedding-3-small',
  },
});
```

**ç’°å¢ƒå¤‰æ•°:**
- `AZURE_OPENAI_ENDPOINT` (å¿…é ˆ)
- `AZURE_OPENAI_API_KEY` (å¿…é ˆ)
- `AZURE_OPENAI_API_VERSION` (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
- `AZURE_OPENAI_CHAT_DEPLOYMENT` (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
- `AZURE_OPENAI_EMBEDDING_DEPLOYMENT` (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)

### Anthropic

```typescript
const anthropic = createLLMProvider({
  type: 'anthropic',
  apiKey: process.env.ANTHROPIC_API_KEY,
  models: {
    chat: 'claude-3-5-sonnet-20241022',
  },
});
```

**ç’°å¢ƒå¤‰æ•°:**
- `ANTHROPIC_API_KEY` (å¿…é ˆ)
- `ANTHROPIC_BASE_URL` (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
- `ANTHROPIC_MODEL` (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)

### Ollama

```typescript
const ollama = createLLMProvider({
  type: 'ollama',
  baseUrl: 'http://localhost:11434',
  models: {
    chat: 'llama3.2',
    embedding: 'nomic-embed-text',
  },
});
```

**ç’°å¢ƒå¤‰æ•°:**
- `OLLAMA_HOST` (ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: `http://localhost:11434`)
- `OLLAMA_MODEL` (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
- `OLLAMA_EMBEDDING_MODEL` (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)

## ğŸ”§ CompletionOptions

```typescript
interface CompletionOptions {
  temperature?: number;      // 0.0 - 2.0
  maxTokens?: number;        // æœ€å¤§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°
  topP?: number;             // 0.0 - 1.0
  frequencyPenalty?: number; // -2.0 - 2.0
  presencePenalty?: number;  // -2.0 - 2.0
  stop?: string[];           // åœæ­¢ã‚·ãƒ¼ã‚±ãƒ³ã‚¹
}
```

## ğŸ§ª ãƒ†ã‚¹ãƒˆ

```bash
pnpm test
```

## ğŸ“š ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹

### ILLMProvider

```typescript
interface ILLMProvider {
  readonly name: string;
  readonly type: LLMProviderType;

  // ãƒãƒ£ãƒƒãƒˆ
  chat(
    messages: ChatMessage[],
    options?: CompletionOptions
  ): Promise<CompletionResult>;

  // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
  streamChat(
    messages: ChatMessage[],
    options?: CompletionOptions
  ): AsyncIterable<CompletionChunk>;

  // åŸ‹ã‚è¾¼ã¿
  embed(texts: string[]): Promise<number[][]>;

  // ä½¿ç”¨é‡
  getUsage(): Promise<UsageStats>;
}
```
